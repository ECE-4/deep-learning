{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPFcj_9YeSjv",
    "outputId": "41a6f135-a6ab-458b-f3b0-150663b3e537"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'preprocessing' from 'tensorflow.keras.layers.experimental' (C:\\Users\\Neil\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v1\\keras\\layers\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d774b5535bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#!pip install -q -U keras-tuner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkerastuner\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\kerastuner\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moracles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtuners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\kerastuner\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperResNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mxception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperXception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperImageAugment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\kerastuner\\applications\\augment.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# dict of functions that create layers for transforms.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'preprocessing' from 'tensorflow.keras.layers.experimental' (C:\\Users\\Neil\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v1\\keras\\layers\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#!pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AuaujtIeSjv",
    "outputId": "13daa3ae-3d71-4403-d978-c18b612feab5"
   },
   "outputs": [],
   "source": [
    "print(\"NumPy version \" + np.__version__)\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_T3qfADzeSjx"
   },
   "outputs": [],
   "source": [
    "## Data Reading ##\n",
    "#tf.data.experimental.CsvDataset(\"data2/train_drug.csv\", \"float32\")\n",
    "path=\"https://pzfczh27edy8hocjobyt5a-on.drv.tw/webserver/dm/\"\n",
    "results = pd.read_csv(path + \"train_targets_scored.csv\")\n",
    "testSet = pd.read_csv(path + \"test_features.csv\")\n",
    "train_features = pd.read_csv(path + \"train_features_court.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSvx7ynYeSjx"
   },
   "outputs": [],
   "source": [
    "## Parameters ##\n",
    "validationProportion = 0.2\n",
    "\n",
    "N = len(train_features) #Nombre d'échantillons testés\n",
    "I = train_features.shape[1]-1 #Nombre de input\n",
    "M = results.shape[1]-1 #Nombre de pathologies obserables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qA94KrOqeSjx"
   },
   "outputs": [],
   "source": [
    "## HYPER parameters ##\n",
    "nbEpoch = 30 \n",
    "learningRate = 0.01 #with the adam optimizer\n",
    "\n",
    "# nombre de couches cachées\n",
    "# nombre de neurones\n",
    "# fonctions d'activation\n",
    "# epsilon (adam)\n",
    "\n",
    "# cf randomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "YlJsB4YDeSjx",
    "outputId": "d2738925-9434-44fd-c3e3-86a21100a440"
   },
   "outputs": [],
   "source": [
    "## Normalization ##\n",
    "maxVal=np.max(np.max(np.abs(train_features.iloc[:,4:])))\n",
    "train_features.iloc[:,4:] = train_features.iloc[:,4:]/maxVal\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "ALQHI59leSjx",
    "outputId": "d3200480-a947-4fa7-a28a-053fc8cd131a"
   },
   "outputs": [],
   "source": [
    "## replacing sig_id by drug_id ##\n",
    "dataSet = train_features.join(results, lsuffix='sig_id', rsuffix='sig_id')\n",
    "dataSet = dataSet.drop(columns=['sig_idsig_id'])\n",
    "\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "4kXl-0dweSjx",
    "outputId": "4cd5a0c3-f13d-4249-fcb8-38ba46919d5e"
   },
   "outputs": [],
   "source": [
    "## Shuffling ##\n",
    "dataSet = dataSet.reindex(np.random.permutation(dataSet.index))\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "S5jNik3CeSjy",
    "outputId": "871ebf82-6515-46e6-ff6f-72b7c775b419"
   },
   "outputs": [],
   "source": [
    "## Replacing categories values by numbers ##\n",
    "features_to_convert=['cp_type','cp_time','cp_dose']\n",
    "for feat in features_to_convert:\n",
    "    dataSet[feat] = pd.Categorical(dataSet[feat])\n",
    "    dataSet[feat] = dataSet[feat].cat.codes\n",
    "    \n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxaiGCbNeSjy",
    "outputId": "8a3f6940-d6ad-4d7d-fd8f-27bd27d6b78e"
   },
   "outputs": [],
   "source": [
    "## Splitting into training and validation ##\n",
    "trainingSize = int((1-validationProportion) * N)\n",
    "\n",
    "trainingSet = dataSet.iloc[:trainingSize,:] \n",
    "validationSet = dataSet.iloc[trainingSize:,:]\n",
    "\n",
    "print(\"Training size:\", len(trainingSet))\n",
    "print(\"Validation size:\", len(validationSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "1k8CvRCxeSjy",
    "outputId": "7458fae8-4556-4174-dd20-f2a14f78e92a"
   },
   "outputs": [],
   "source": [
    "XTrain = trainingSet.iloc[:,:I]\n",
    "YTrain = trainingSet.iloc[:,I:]\n",
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "g3Ehm9FmeSjy",
    "outputId": "151e92c8-789f-452b-e773-5d0a30b4bd34"
   },
   "outputs": [],
   "source": [
    "## Batching ##\n",
    "\"\"\"\n",
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), dataframe))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds\n",
    "\n",
    "trainingds = df_to_dataset(trainingSet)\n",
    "trainingds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsKJvkeseSjz"
   },
   "outputs": [],
   "source": [
    "## Training ##\n",
    "\n",
    "model_non_optimized = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(512, activation = 'softplus'),\n",
    "                                    tf.keras.layers.Dense(M, activation=tf.nn.sigmoid)])\n",
    "\n",
    "#sigmoid is more appropriate rather softmax because we are multiple factors of cancer \n",
    "\n",
    "model_non_optimized.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsGXzW-8pmjx"
   },
   "outputs": [],
   "source": [
    "def model_generation(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten())\n",
    "  \n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-1024\n",
    "  hp_units = hp.Int('units', min_value = 32, max_value = 1024, step = 32)\n",
    "  hp_units_2 = hp.Int('units_2', min_value = 32, max_value = 1024, step = 32)\n",
    "  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "  model.add(keras.layers.Dense(units = hp_units_2, activation = 'softplus'))\n",
    "  model.add(keras.layers.Dense(M, activation = tf.nn.sigmoid))\n",
    "\n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, 0.0001 or 0.000001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4, 1e-6]) \n",
    "  \n",
    "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss='binary_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FypR5gfLeSjz",
    "outputId": "5941e69c-670a-4cf5-f222-7dd3590cceec"
   },
   "outputs": [],
   "source": [
    "#Resultats avant hyperparameters\n",
    "model_non_optimized.fit(XTrain, YTrain, epochs=nbEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wMY34fMqwTX"
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_generation,\n",
    "                     objective = 'accuracy', \n",
    "                     max_epochs = 10\n",
    "                     )             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ2UL1WGoSE_"
   },
   "outputs": [],
   "source": [
    "#function to clear the output when we look for the best hyperparameters\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1097kqQ5oTT3"
   },
   "outputs": [],
   "source": [
    "tuner.search(XTrain, YTrain, epochs = 10, callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "optimized_param = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {optimized_param.get('units')}, in the second it's {optimized_param.get('units_2')} and the optimal learning rate for the optimizer\n",
    "is {optimized_param.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt2flIknr_N5"
   },
   "source": [
    "### on relance le modèle avec nos paramètres optimisés\n",
    "model_optimized = tuner.hypermodel.build(optimized_param)\n",
    "model_optimized.fit(XTrain, YTrain, epochs=nbEpoch)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
